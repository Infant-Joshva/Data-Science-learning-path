{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0324ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.6-cp310-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.1 (from langchain-community)\n",
      "  Downloading langchain_core-1.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from langchain-community) (2.0.42)\n",
      "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith<1.0.0,>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.4.41-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.1->langchain-community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.14.1)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.1)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\infan\\onedrive\\desktop\\data science guvi py(git)\\.venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.6/2.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 6.9 MB/s  0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 6.2 MB/s  0:00:00\n",
      "Downloading langchain_core-1.0.3-py3-none-any.whl (469 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
      "Downloading langsmith-0.4.41-py3-none-any.whl (399 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 1.6/2.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 6.6 MB/s  0:00:00\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading pymupdf-1.26.6-cp310-abi3-win_amd64.whl (18.4 MB)\n",
      "   ---------------------------------------- 0.0/18.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.6/18.4 MB 7.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 3.1/18.4 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 4.7/18.4 MB 7.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 6.3/18.4 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.9/18.4 MB 7.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 9.4/18.4 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 11.0/18.4 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 12.6/18.4 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 14.2/18.4 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 15.7/18.4 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 17.0/18.4 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.4/18.4 MB 7.1 MB/s  0:00:02\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl (506 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, sniffio, requests, python-dotenv, pymupdf, pydantic-core, mypy-extensions, marshmallow, jsonpointer, httpx-sse, h11, annotated-types, typing-inspect, requests-toolbelt, pydantic, jsonpatch, httpcore, anyio, pydantic-settings, httpx, dataclasses-json, langsmith, langchain-core, langchain-text-splitters, langchain-classic, langchain-community\n",
      "\n",
      "   -- -------------------------------------  2/27 [sniffio]\n",
      "  Attempting uninstall: requests\n",
      "   -- -------------------------------------  2/27 [sniffio]\n",
      "    Found existing installation: requests 2.32.4\n",
      "   -- -------------------------------------  2/27 [sniffio]\n",
      "    Uninstalling requests-2.32.4:\n",
      "   -- -------------------------------------  2/27 [sniffio]\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "   -- -------------------------------------  2/27 [sniffio]\n",
      "   ---- -----------------------------------  3/27 [requests]\n",
      "   ---- -----------------------------------  3/27 [requests]\n",
      "   ----- ----------------------------------  4/27 [python-dotenv]\n",
      "   ------- --------------------------------  5/27 [pymupdf]\n",
      "   ------- --------------------------------  5/27 [pymupdf]\n",
      "   ------- --------------------------------  5/27 [pymupdf]\n",
      "   ------- --------------------------------  5/27 [pymupdf]\n",
      "   ------- --------------------------------  5/27 [pymupdf]\n",
      "   ------- --------------------------------  5/27 [pymupdf]\n",
      "   ------- --------------------------------  5/27 [pymupdf]\n",
      "   ---------- -----------------------------  7/27 [mypy-extensions]\n",
      "   ----------- ----------------------------  8/27 [marshmallow]\n",
      "   -------------- ------------------------- 10/27 [httpx-sse]\n",
      "   ---------------- ----------------------- 11/27 [h11]\n",
      "   ---------------- ----------------------- 11/27 [h11]\n",
      "   -------------------- ------------------- 14/27 [requests-toolbelt]\n",
      "   -------------------- ------------------- 14/27 [requests-toolbelt]\n",
      "   -------------------- ------------------- 14/27 [requests-toolbelt]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ---------------------- ----------------- 15/27 [pydantic]\n",
      "   ------------------------- -------------- 17/27 [httpcore]\n",
      "   ------------------------- -------------- 17/27 [httpcore]\n",
      "   ------------------------- -------------- 17/27 [httpcore]\n",
      "   ------------------------- -------------- 17/27 [httpcore]\n",
      "   -------------------------- ------------- 18/27 [anyio]\n",
      "   -------------------------- ------------- 18/27 [anyio]\n",
      "   -------------------------- ------------- 18/27 [anyio]\n",
      "   -------------------------- ------------- 18/27 [anyio]\n",
      "   ---------------------------- ----------- 19/27 [pydantic-settings]\n",
      "   ---------------------------- ----------- 19/27 [pydantic-settings]\n",
      "   ----------------------------- ---------- 20/27 [httpx]\n",
      "   ----------------------------- ---------- 20/27 [httpx]\n",
      "   ----------------------------- ---------- 20/27 [httpx]\n",
      "   ----------------------------- ---------- 20/27 [httpx]\n",
      "   ------------------------------- -------- 21/27 [dataclasses-json]\n",
      "   -------------------------------- ------- 22/27 [langsmith]\n",
      "   -------------------------------- ------- 22/27 [langsmith]\n",
      "   -------------------------------- ------- 22/27 [langsmith]\n",
      "   -------------------------------- ------- 22/27 [langsmith]\n",
      "   -------------------------------- ------- 22/27 [langsmith]\n",
      "   -------------------------------- ------- 22/27 [langsmith]\n",
      "   -------------------------------- ------- 22/27 [langsmith]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ---------------------------------- ----- 23/27 [langchain-core]\n",
      "   ----------------------------------- ---- 24/27 [langchain-text-splitters]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   ------------------------------------- -- 25/27 [langchain-classic]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   -------------------------------------- - 26/27 [langchain-community]\n",
      "   ---------------------------------------- 27/27 [langchain-community]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.11.0 dataclasses-json-0.6.7 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 jsonpatch-1.33 jsonpointer-3.0.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.0.3 langchain-text-splitters-1.0.0 langsmith-0.4.41 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-2.12.4 pydantic-core-2.41.5 pydantic-settings-2.11.0 pymupdf-1.26.6 python-dotenv-1.2.1 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 typing-inspect-0.9.0 typing-inspection-0.4.2 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fc38bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"C:/Users/infan/OneDrive/Desktop/Data Science Guvi Py(Git)/Data-Science-learning-path/DS-Practice-Notebooks/DS04-DL-NLP/RAG/sample.pdf\")\n",
    "loader = PyMuPDFLoader(file_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37cd0ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': '', 'creationdate': 'D:20251107113621', 'source': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'file_path': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'total_pages': 5, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20251107113621', 'page': 0}, page_content='Page 1: Introduction to Artificial Intelligence\\nArtificial Intelligence (AI) refers to systems designed to perform tasks that mimic human intelligence.\\nIt encompasses areas such as reasoning, learning, perception, and problem-solving.\\nAI applications are now embedded in everyday tools like smartphones, virtual assistants, and even\\nsmart home devices.'),\n",
       " Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': '', 'creationdate': 'D:20251107113621', 'source': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'file_path': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'total_pages': 5, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20251107113621', 'page': 1}, page_content='Page 2: Machine Learning Basics\\nMachine Learning (ML) is a subset of AI that enables systems to learn and improve from experience\\nautomatically. It involves feeding algorithms with data to make predictions or decisions without\\nexplicit programming.\\nThe three main types of ML are:\\n1. Supervised Learning\\n2. Unsupervised Learning\\n3. Reinforcement Learning'),\n",
       " Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': '', 'creationdate': 'D:20251107113621', 'source': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'file_path': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'total_pages': 5, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20251107113621', 'page': 2}, page_content='Page 3: Deep Learning Overview\\nDeep Learning (DL) is a specialized branch of ML that uses neural networks with multiple layers to\\nanalyze various levels of data abstraction. DL has enabled breakthroughs in image recognition,\\nspeech processing, and autonomous driving.\\nPopular deep learning frameworks include TensorFlow, PyTorch, and Keras.'),\n",
       " Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': '', 'creationdate': 'D:20251107113621', 'source': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'file_path': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'total_pages': 5, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20251107113621', 'page': 3}, page_content='Page 4: Natural Language Processing (NLP)\\nNLP allows machines to understand, interpret, and generate human language. It powers\\napplications like chatbots, translation services, and sentiment analysis.\\nKey techniques include tokenization, stemming, lemmatization, and named entity recognition (NER).'),\n",
       " Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': '', 'creationdate': 'D:20251107113621', 'source': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'file_path': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'total_pages': 5, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20251107113621', 'page': 4}, page_content='Page 5: AI in Real-world Applications\\nAI is transforming industries through automation and intelligent decision-making. Here are a few\\nexamples:\\n- Healthcare: Disease prediction, medical imaging, and drug discovery.\\n- Finance: Fraud detection and algorithmic trading.\\n- Agriculture: Crop monitoring and yield prediction.\\n- Education: Personalized learning and automated grading.\\nAI continues to evolve rapidly, shaping the future of technology and society.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eabddc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': '', 'creationdate': 'D:20251107113621', 'source': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'file_path': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'total_pages': 5, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20251107113621', 'page': 0}, page_content='Page 1: Introduction to Artificial Intelligence\\nArtificial Intelligence (AI) refers to systems designed to perform tasks that mimic human intelligence.\\nIt encompasses areas such as reasoning, learning, perception, and problem-solving.\\nAI applications are now embedded in everyday tools like smartphones, virtual assistants, and even\\nsmart home devices.')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3061fe40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schema of DB\n",
    "\n",
    "# {\n",
    "#     id:[],\n",
    "#     document:[],\n",
    "#     emmbedding:[],\n",
    "#     metadata:[]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20849c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Page 1: Introduction to Artificial Intelligence\n",
      "Artificial Intelligence (AI) refers to systems designed to perform tasks that mimic human intelligence.\n",
      "It encompasses areas such as reasoning, learning, perception, and problem-solving.\n",
      "AI applications are now embedded in everyday tools like smartphones, virtual assistants, and even\n",
      "smart home devices.\n",
      "{'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': '', 'creationdate': 'D:20251107113621', 'source': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'file_path': 'C:\\\\Users\\\\infan\\\\OneDrive\\\\Desktop\\\\Data Science Guvi Py(Git)\\\\Data-Science-learning-path\\\\DS-Practice-Notebooks\\\\DS04-DL-NLP\\\\RAG\\\\sample.pdf', 'total_pages': 5, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20251107113621', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# Split based on page type\n",
    "\n",
    "Data={\n",
    "    'id':[],\n",
    "    'text':[],\n",
    "    'metadata':[]\n",
    "}\n",
    "\n",
    "for page in docs:\n",
    "    print(page.metadata['page'])\n",
    "    print(page.page_content)\n",
    "    print(page.metadata)\n",
    "    Data['id'].append(page.metadata['page'])\n",
    "    Data['text'].append(page.page_content)\n",
    "    Data['metadata'].append(page.metadata)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d434278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split based on regressive type \n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=20, chunk_overlap=5)\n",
    "texts = text_splitter.split_text(' '.join([page.page_content for page in docs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a55434d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Page 1: Introduction',\n",
       " 'to Artificial',\n",
       " 'Intelligence',\n",
       " 'Artificial',\n",
       " 'Intelligence (AI)',\n",
       " '(AI) refers to',\n",
       " 'to systems designed',\n",
       " 'to perform tasks',\n",
       " 'that mimic human',\n",
       " 'intelligence.',\n",
       " 'It encompasses',\n",
       " 'areas such as',\n",
       " 'as reasoning,',\n",
       " 'learning,',\n",
       " 'perception, and',\n",
       " 'problem-solving.',\n",
       " 'AI applications are',\n",
       " 'are now embedded in',\n",
       " 'in everyday tools',\n",
       " 'like smartphones,',\n",
       " 'virtual assistants,',\n",
       " 'and even',\n",
       " 'smart home devices.',\n",
       " 'Page 2: Machine',\n",
       " 'Learning Basics',\n",
       " 'Machine Learning',\n",
       " '(ML) is a subset of',\n",
       " 'of AI that enables',\n",
       " 'systems to learn',\n",
       " 'and improve from',\n",
       " 'from experience',\n",
       " 'automatically. It',\n",
       " 'It involves feeding',\n",
       " 'algorithms with',\n",
       " 'with data to make',\n",
       " 'make predictions or',\n",
       " 'or decisions',\n",
       " 'without',\n",
       " 'explicit',\n",
       " 'programming.',\n",
       " 'The three main',\n",
       " 'main types of ML',\n",
       " 'ML are:',\n",
       " '1. Supervised',\n",
       " 'Learning',\n",
       " '2. Unsupervised',\n",
       " 'Learning',\n",
       " '3. Reinforcement',\n",
       " 'Learning Page 3:',\n",
       " '3: Deep Learning',\n",
       " 'Overview',\n",
       " 'Deep Learning (DL)',\n",
       " '(DL) is a',\n",
       " 'is a specialized',\n",
       " 'branch of ML that',\n",
       " 'that uses neural',\n",
       " 'networks with',\n",
       " 'with multiple',\n",
       " 'layers to',\n",
       " 'analyze various',\n",
       " 'levels of data',\n",
       " 'data abstraction.',\n",
       " 'DL has enabled',\n",
       " 'breakthroughs in',\n",
       " 'in image',\n",
       " 'recognition,',\n",
       " 'speech processing,',\n",
       " 'and autonomous',\n",
       " 'driving.',\n",
       " 'Popular deep',\n",
       " 'deep learning',\n",
       " 'frameworks include',\n",
       " 'TensorFlow,',\n",
       " 'PyTorch, and Keras.',\n",
       " 'Page 4: Natural',\n",
       " 'Language Processing',\n",
       " '(NLP)',\n",
       " 'NLP allows machines',\n",
       " 'to understand,',\n",
       " 'interpret, and',\n",
       " 'and generate human',\n",
       " 'language. It powers',\n",
       " 'applications like',\n",
       " 'like chatbots,',\n",
       " 'translation',\n",
       " 'services, and',\n",
       " 'and sentiment',\n",
       " 'analysis.',\n",
       " 'Key techniques',\n",
       " 'include',\n",
       " 'tokenization,',\n",
       " 'stemming,',\n",
       " 'lemmatization, and',\n",
       " 'and named entity',\n",
       " 'recognition (NER).',\n",
       " 'Page 5: AI in',\n",
       " 'in Real-world',\n",
       " 'Applications',\n",
       " 'AI is transforming',\n",
       " 'industries through',\n",
       " 'automation and',\n",
       " 'and intelligent',\n",
       " 'decision-making.',\n",
       " 'Here are a few',\n",
       " 'examples:',\n",
       " '- Healthcare:',\n",
       " 'Disease prediction,',\n",
       " 'medical imaging,',\n",
       " 'and drug discovery.',\n",
       " '- Finance: Fraud',\n",
       " 'detection and',\n",
       " 'and algorithmic',\n",
       " 'trading.',\n",
       " '- Agriculture: Crop',\n",
       " 'Crop monitoring and',\n",
       " 'and yield',\n",
       " 'prediction.',\n",
       " '- Education:',\n",
       " 'Personalized',\n",
       " 'learning and',\n",
       " 'and automated',\n",
       " 'grading.',\n",
       " 'AI continues to',\n",
       " 'to evolve rapidly,',\n",
       " 'shaping the future',\n",
       " 'of technology and',\n",
       " 'and society.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29917b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
